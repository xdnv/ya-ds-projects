# Проект: Определение токсичных комментариев

*Цель: Обучить модель классифицировать комментарии на позитивные и негативные.*
Интернет-магазин запускает новый сервис: теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах.
То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75.

*Учебная задача: научиться...*
1. Работать с предобученными моделями нейросетей;
2. векторизовать текстовые данные для машинного обучения.

## Программа исследования
- Загрузить и подготовить данные;
- обучить модели на данных, разделённых на обучающую, валидационную и тестовую выборки;
- протестировать модели с оптимальными гиперапраметрами;

## Результаты
- Данные загружены, проведён первичный анализ
- Тексты очищены от не-алфавитных знаков и приведены к нижнему регистру
- Удалено 1293 дубликата
- Датасет сокращён до 10% из-за ограничения по доступным ресурсам. Баланс классов сохранён. Для развёртывания в продуктиве необходимо будет повторить расчёты на полном массиве данных на GPU.
- Проведён эмбеддинг с помощью модели BERT, факторы и классы обучающей выборки сбалансированы методом апсемплинга.
- Проведено обучение моделей Логистической регрессии, случайного леса, бустинговых моделей LightGBM и CatBoost
- Проведено тестирование производительности и расчёт f1-метрики моделей
- Все опробованные модели адекватны и применимы в работе, незначительно лидирует LGBMClassifier

## Стек и применённые подходы
* pandas, sklearn, numpy, LightGBM, CatBoost, pyTorch, BERT-toxic